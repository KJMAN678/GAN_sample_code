{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cedro3.com/ai/keras-anogan-anomaly/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils. generic_utils import Progbar\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose, Flatten\n",
    "from keras.layers.core import Activation\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import math, cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "#from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 16 # バッチサイズ\n",
    "EPOCH = 300 # エポック数\n",
    "DIM   = 30  # 入力する次元数\n",
    "LR    = 0.001 # 学習率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, input_dim, image_shape):\n",
    "        INITIAL_CHANNELS = 128\n",
    "        INITIAL_SIZE = 7\n",
    " \n",
    "        inputs = Input((input_dim,))\n",
    "        fc1 = Dense(input_dim=input_dim, units=INITIAL_CHANNELS * INITIAL_SIZE * INITIAL_SIZE)(inputs)\n",
    "        fc1 = BatchNormalization()(fc1)\n",
    "        fc1 = LeakyReLU(0.2)(fc1)\n",
    "        fc2 = Reshape((INITIAL_SIZE, INITIAL_SIZE, INITIAL_CHANNELS), input_shape=(INITIAL_CHANNELS * INITIAL_SIZE * INITIAL_SIZE,))(fc1)\n",
    "        up1 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(fc2)\n",
    "        conv1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        conv1 = Activation('relu')(conv1)\n",
    "        up2 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv1)\n",
    "        conv2 = Conv2D(image_shape[2], (5, 5), padding='same')(up2)\n",
    "        outputs = Activation('tanh')(conv2)\n",
    " \n",
    "        self.model = Model(inputs=[inputs], outputs=[outputs])\n",
    " \n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self, input_shape):\n",
    "        inputs = Input(input_shape)\n",
    "        conv1 = Conv2D(64, (5, 5), padding='same')(inputs)\n",
    "        conv1 = LeakyReLU(0.2)(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        conv2 = Conv2D(128, (5, 5), padding='same')(pool1)\n",
    "        conv2 = LeakyReLU(0.2)(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        fc1 = Flatten()(pool2)\n",
    "        fc1 = Dense(1)(fc1)\n",
    "        outputs = Activation('sigmoid')(fc1)\n",
    " \n",
    "        self.model = Model(inputs=[inputs], outputs=[outputs])\n",
    " \n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, input_dim, image_shape):\n",
    "        self.input_dim = input_dim\n",
    "        self.d = Discriminator(image_shape).get_model()\n",
    "        self.g = Generator(input_dim, image_shape).get_model()\n",
    " \n",
    "    def compile(self, g_optim, d_optim):\n",
    "        self.d.trainable = False\n",
    "        self.dcgan = Sequential([self.g, self.d])\n",
    "        self.dcgan.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "        self.d.trainable = True\n",
    "        self.d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    " \n",
    "    def train(self, epochs, batch_size, X_train):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(X_train)\n",
    "            n_iter = X_train.shape[0] // batch_size\n",
    "            progress_bar = Progbar(target=n_iter)\n",
    "            for index in range(n_iter):\n",
    "                # create random noise -> N latent vectors\n",
    "                noise = np.random.uniform(-1, 1, size=(batch_size, self.input_dim))\n",
    " \n",
    "                # load real data & generate fake data\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                for i in range(batch_size):\n",
    "                    if np.random.random() > 0.5:\n",
    "                        image_batch[i] = np.fliplr(image_batch[i])\n",
    "                    if np.random.random() > 0.5:\n",
    "                        image_batch[i] = np.flipud(image_batch[i])\n",
    "                generated_images = self.g.predict(noise, verbose=0)\n",
    " \n",
    "                # attach label for training discriminator\n",
    "                X = np.concatenate((image_batch, generated_images))\n",
    "                y = np.array([1] * batch_size + [0] * batch_size)\n",
    " \n",
    "                # training discriminator\n",
    "                d_loss = self.d.train_on_batch(X, y)\n",
    " \n",
    "                # training generator\n",
    "                g_loss = self.dcgan.train_on_batch(noise, np.array([1] * batch_size))\n",
    " \n",
    "                progress_bar.update(index, values=[('g', g_loss), ('d', d_loss)])\n",
    "            g_losses.append(g_loss)\n",
    "            d_losses.append(d_loss)\n",
    "            if (epoch+1)%10 == 0:\n",
    "                image = self.combine_images(generated_images)\n",
    "                image = (image + 1) / 2.0 * 255.0\n",
    "                cv2.imwrite('./result/' + str(epoch) + \".png\", image)\n",
    "            print('\\nEpoch' + str(epoch) + \" end\")\n",
    " \n",
    "            # save weights for each epoch\n",
    "            if (epoch+1)%50 == 0:\n",
    "                self.g.save_weights('weights/generator_' + str(epoch) + '.h5', True)\n",
    "                self.d.save_weights('weights/discriminator_' + str(epoch) + '.h5', True)\n",
    "        return g_losses, d_losses\n",
    " \n",
    "    def load_weights(self, g_weight, d_weight):\n",
    "        self.g.load_weights(g_weight)\n",
    "        self.d.load_weights(d_weight)\n",
    " \n",
    "    def combine_images(self, generated_images):\n",
    "        num = generated_images.shape[0]\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num) / width))\n",
    "        shape = generated_images.shape[1:4]\n",
    "        image = np.zeros((height * shape[0], width * shape[1], shape[2]),\n",
    "                         dtype=generated_images.dtype)\n",
    "        for index, img in enumerate(generated_images):\n",
    "            i = int(index / width)\n",
    "            j = index % width\n",
    "            image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1], :] = img[:, :, :]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnoGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_residual(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANOGAN(object):\n",
    "    def __init__(self, input_dim, g):\n",
    "        self.input_dim = input_dim\n",
    "        self.g = g\n",
    "        g.trainable = False\n",
    "        # Input layer cann't be trained. Add new layer as same size & same distribution\n",
    "        anogan_in = Input(shape=(input_dim,))\n",
    "        g_in = Dense((input_dim), activation='tanh', trainable=True)(anogan_in)\n",
    "        g_out = g(g_in)\n",
    "        self.model = Model(inputs=anogan_in, outputs=g_out)\n",
    "        self.model_weight = None\n",
    " \n",
    "    def compile(self, optim):\n",
    "        self.model.compile(loss=sum_of_residual, optimizer=optim)\n",
    "        K.set_learning_phase(0)\n",
    " \n",
    "    def compute_anomaly_score(self, x, iterations=300):\n",
    "        z = np.random.uniform(-1, 1, size=(1, self.input_dim))\n",
    " \n",
    "        # learning for changing latent\n",
    "        loss = self.model.fit(z, x, batch_size=1, epochs=iterations, verbose=0)\n",
    "        loss = loss.history['loss'][-1]\n",
    "        similar_data = self.model.predict_on_batch(z)\n",
    " \n",
    "        return loss, similar_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 6742\n",
      "test_data: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shimizukoji\\anaconda3\\envs\\AnoGAN\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/421 [..............................] - ETA: 5:53 - g: 0.7368 - d: 0.4697   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shimizukoji\\anaconda3\\envs\\AnoGAN\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/421 [============================>.] - ETA: 0s - g: 2.4769 - d: 0.0378\n",
      "Epoch0 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 5.5611 - d: 0.1510\n",
      "Epoch1 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 3.8372 - d: 0.1650\n",
      "Epoch2 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 3.5484 - d: 0.2162\n",
      "Epoch3 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 4.9051 - d: 0.1536\n",
      "Epoch4 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 7.0900 - d: 0.1242\n",
      "Epoch5 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 5.5515 - d: 0.1358\n",
      "Epoch6 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 6.7821 - d: 0.0708\n",
      "Epoch7 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 7.1436 - d: 0.1116\n",
      "Epoch8 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 6.0151 - d: 0.1167\n",
      "Epoch9 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 8.3645 - d: 0.0532\n",
      "Epoch10 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 7.1722 - d: 0.0664\n",
      "Epoch11 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 10.5226 - d: 0.0222\n",
      "Epoch12 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 8.4427 - d: 0.0885\n",
      "Epoch13 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 10.8510 - d: 0.0118\n",
      "Epoch14 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 8.4483 - d: 0.0856\n",
      "Epoch15 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 7.9091 - d: 0.0462\n",
      "Epoch16 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 10.0946 - d: 0.0121\n",
      "Epoch17 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 10.2382 - d: 0.0766\n",
      "Epoch18 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 8.4933 - d: 0.0170\n",
      "Epoch19 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 8.7020 - d: 0.0962\n",
      "Epoch20 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 8.2555 - d: 0.0078\n",
      "Epoch21 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 14.1657 - d: 0.0337\n",
      "Epoch22 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 7.6309 - d: 0.0614\n",
      "Epoch23 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 10.5166 - d: 0.0123\n",
      "Epoch24 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 11.5515 - d: 0.0624- ETA: 0s - g: 11.5538 - d: 0.062\n",
      "Epoch25 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 12.2935 - d: 0.0040\n",
      "Epoch26 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.6388 - d: 0.0162\n",
      "Epoch27 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 12.3193 - d: 0.0282\n",
      "Epoch28 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 11.6090 - d: 0.0567- \n",
      "Epoch29 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 22.2839 - d: 0.0230\n",
      "Epoch30 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 9.5135 - d: 0.0690\n",
      "Epoch31 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.6718 - d: 0.0322\n",
      "Epoch32 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.3300 - d: 0.0090\n",
      "Epoch33 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.2907 - d: 0.0671\n",
      "Epoch34 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 11.5715 - d: 0.0757\n",
      "Epoch35 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 14.0908 - d: 0.0549\n",
      "Epoch36 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.2678 - d: 0.0635\n",
      "Epoch37 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 14.2335 - d: 0.0267\n",
      "Epoch38 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.5543 - d: 0.0409\n",
      "Epoch39 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.3250 - d: 0.0164\n",
      "Epoch40 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 12.3302 - d: 0.0409\n",
      "Epoch41 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 13.4857 - d: 0.0104\n",
      "Epoch42 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 16.8549 - d: 0.0526\n",
      "Epoch43 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.1753 - d: 0.0410\n",
      "Epoch44 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 18.7757 - d: 0.0127\n",
      "Epoch45 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.4546 - d: 0.0475\n",
      "Epoch46 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.2214 - d: 0.0424\n",
      "Epoch47 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 11.4368 - d: 0.0526- ETA: 1s - g:\n",
      "Epoch48 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 10.8402 - d: 0.0622\n",
      "Epoch49 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 88.6574 - d: 0.0034\n",
      "Epoch50 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.0766 - d: 0.0019\n",
      "Epoch51 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 22.4502 - d: 1.1958e-06\n",
      "Epoch52 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 24.9157 - d: 1.5800e-05\n",
      "Epoch53 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 33.8894 - d: 0.0015\n",
      "Epoch54 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.6809 - d: 1.4002e-05\n",
      "Epoch55 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 25.3241 - d: 2.9229e-06\n",
      "Epoch56 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 25.0985 - d: 8.4732e-07\n",
      "Epoch57 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 25.4884 - d: 1.1690e-06\n",
      "Epoch58 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 19.1850 - d: 1.9786e-04\n",
      "Epoch59 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 11.7765 - d: 1.5362e-05\n",
      "Epoch60 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 11.7079 - d: 4.7570e-06\n",
      "Epoch61 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 12.6194 - d: 2.4171e-06\n",
      "Epoch62 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.0618 - d: 1.9130e-06\n",
      "Epoch63 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 78.0237 - d: 7.8286e-07\n",
      "Epoch64 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 26.8397 - d: 6.3124e-08\n",
      "Epoch65 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 17.3338 - d: 9.4150e-07\n",
      "Epoch66 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.5352 - d: 8.5459e-07\n",
      "Epoch67 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 13.8788 - d: 6.2475e-07\n",
      "Epoch68 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 39.3970 - d: 1.9801e-07\n",
      "Epoch69 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 46.1407 - d: 8.9851e-08\n",
      "Epoch70 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 30.8009 - d: 3.3486e-07\n",
      "Epoch71 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 16.7588 - d: 4.5692e-07\n",
      "Epoch72 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 14.9212 - d: 3.0884e-07- ETA: 0s - g: 14.9215 - d: 3.0527\n",
      "Epoch73 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.1156 - d: 1.7790e-07\n",
      "Epoch74 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 77.5165 - d: 2.3698e-07\n",
      "Epoch75 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 29.5260 - d: 1.9027e-08\n",
      "Epoch76 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 23.5814 - d: 3.8322e-08\n",
      "Epoch77 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.2125 - d: 1.6478e-07\n",
      "Epoch78 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.6267 - d: 1.4746e-07\n",
      "Epoch79 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 47.0199 - d: 3.0741e-09\n",
      "Epoch80 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 26.9209 - d: 3.1373e-08\n",
      "Epoch81 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 15.9145 - d: 8.8313e-08\n",
      "Epoch82 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 16.6461 - d: 4.7314e-08\n",
      "Epoch83 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 55.7362 - d: 1.9691e-08\n",
      "Epoch84 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 38.2010 - d: 2.6933e-09\n",
      "Epoch85 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 23.5951 - d: 1.9223e-08\n",
      "Epoch86 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 17.7095 - d: 2.1404e-08\n",
      "Epoch87 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 18.5261 - d: 1.7123e-08\n",
      "Epoch88 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 47.4767 - d: 7.6093e-09\n",
      "Epoch89 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 51.8730 - d: 3.3446e-09\n",
      "Epoch90 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.4354 - d: 3.7952e-10\n",
      "Epoch91 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4071 - d: 5.5700e-10\n",
      "Epoch92 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 42.2823 - d: 6.8839e-10\n",
      "Epoch93 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.5548 - d: 7.0017e-10\n",
      "Epoch94 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.1625 - d: 6.8715e-10\n",
      "Epoch95 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3368 - d: 4.7970e-10\n",
      "Epoch96 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.3627 - d: 3.1669e-10\n",
      "Epoch97 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.1944 - d: 1.4219e-10\n",
      "Epoch98 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.7474 - d: 1.9789e-10\n",
      "Epoch99 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.3363 - d: 7.5486e-09\n",
      "Epoch100 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 19.9802 - d: 2.1008e-09\n",
      "Epoch101 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 54.8827 - d: 6.4998e-10\n",
      "Epoch102 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 45.2131 - d: 1.6101e-10\n",
      "Epoch103 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.2196 - d: 1.6320e-10\n",
      "Epoch104 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.1915 - d: 9.5683e-11- ETA: 4s\n",
      "Epoch105 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 22.2509 - d: 9.1373e-10\n",
      "Epoch106 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.7999 - d: 7.1574e-10\n",
      "Epoch107 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 73.2557 - d: 1.5728e-10\n",
      "Epoch108 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 38.8642 - d: 1.0283e-10\n",
      "Epoch109 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.7559 - d: 3.5073e-11\n",
      "Epoch110 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 45.2571 - d: 3.0907e-11- ETA: 0s - g: 45.2443 - d: 3.157\n",
      "Epoch111 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 33.8400 - d: 2.0230e-11\n",
      "Epoch112 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8487 - d: 2.6668e-11\n",
      "Epoch113 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.3370 - d: 9.8413e-12\n",
      "Epoch114 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5273 - d: 1.4450e-11\n",
      "Epoch115 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.5888 - d: 8.9634e-12\n",
      "Epoch116 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 40.5441 - d: 9.3325e-12\n",
      "Epoch117 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 39.4580 - d: 6.4208e-12\n",
      "Epoch118 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 23.9400 - d: 1.5794e-10\n",
      "Epoch119 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 28.2276 - d: 9.9494e-11- ETA: 1s \n",
      "Epoch120 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 55.9590 - d: 1.1368e-11\n",
      "Epoch121 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7532 - d: 6.7266e-12\n",
      "Epoch122 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 25.4851 - d: 6.1104e-11\n",
      "Epoch123 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 30.1171 - d: 3.7749e-11\n",
      "Epoch124 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 50.3124 - d: 4.3373e-12\n",
      "Epoch125 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7930 - d: 4.0583e-12\n",
      "Epoch126 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 25.9931 - d: 2.1084e-11\n",
      "Epoch127 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 48.5474 - d: 1.9765e-11\n",
      "Epoch128 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 39.9917 - d: 1.0903e-12\n",
      "Epoch129 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 27.3907 - d: 2.7362e-11\n",
      "Epoch130 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.2241 - d: 5.3352e-11\n",
      "Epoch131 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 52.8534 - d: 3.2681e-12\n",
      "Epoch132 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.6392 - d: 1.1115e-12- ETA: 0s - g: 31.7601 - \n",
      "Epoch133 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 27.2504 - d: 7.3394e-12\n",
      "Epoch134 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 39.2106 - d: 1.3912e-04\n",
      "Epoch135 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.7641 - d: 1.8066e-10\n",
      "Epoch136 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.8054 - d: 1.7612e-10\n",
      "Epoch137 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.9525 - d: 1.5668e-10\n",
      "Epoch138 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.9931 - d: 1.5149e-10\n",
      "Epoch139 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 21.9536 - d: 1.5784e-10\n",
      "Epoch140 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 26.1306 - d: 1.1186e-08\n",
      "Epoch141 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 20.3577 - d: 4.3558e-09\n",
      "Epoch142 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 23.9430 - d: 1.3609e-09\n",
      "Epoch143 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 25.3093 - d: 7.5679e-10\n",
      "Epoch144 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.3173 - d: 5.1905e-10\n",
      "Epoch145 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 30.5429 - d: 1.2000e-10\n",
      "Epoch146 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.4673 - d: 4.4099e-11\n",
      "Epoch147 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.2221 - d: 2.1858e-11\n",
      "Epoch148 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 31.0650 - d: 1.4222e-11\n",
      "Epoch149 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.3574 - d: 6.5126e-12\n",
      "Epoch150 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.7017 - d: 4.2032e-12\n",
      "Epoch151 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.4845 - d: 3.1477e-12\n",
      "Epoch152 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.5144 - d: 2.1778e-12\n",
      "Epoch153 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 33.1330 - d: 1.6949e-12\n",
      "Epoch154 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 32.6043 - d: 1.2956e-12\n",
      "Epoch155 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 33.8202 - d: 7.7976e-13\n",
      "Epoch156 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 33.7869 - d: 5.8144e-13\n",
      "Epoch157 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 33.1510 - d: 5.5610e-13\n",
      "Epoch158 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.2682 - d: 3.7635e-13\n",
      "Epoch159 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.1991 - d: 2.8514e-13\n",
      "Epoch160 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.0183 - d: 2.6604e-13\n",
      "Epoch161 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.4048 - d: 2.2061e-13-\n",
      "Epoch162 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.3507 - d: 1.8814e-13\n",
      "Epoch163 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.5048 - d: 1.7250e-13\n",
      "Epoch164 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.5482 - d: 1.4787e-13\n",
      "Epoch165 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.7439 - d: 1.3922e-13\n",
      "Epoch166 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.2657 - d: 1.3968e-13\n",
      "Epoch167 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.5823 - d: 1.2802e-13\n",
      "Epoch168 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.9267 - d: 1.1401e-13- ETA: 1s - g: \n",
      "Epoch169 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.4904 - d: 1.4516e-13\n",
      "Epoch170 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.2720 - d: 1.1348e-13\n",
      "Epoch171 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.1626 - d: 1.0941e-13\n",
      "Epoch172 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.8638 - d: 1.0137e-13\n",
      "Epoch173 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.5634 - d: 1.0053e-13\n",
      "Epoch174 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.1007 - d: 8.8295e-14\n",
      "Epoch175 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.5963 - d: 6.6190e-14\n",
      "Epoch176 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8522 - d: 6.8603e-14\n",
      "Epoch177 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8471 - d: 6.6859e-14\n",
      "Epoch178 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.6676 - d: 7.7339e-14\n",
      "Epoch179 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.4820 - d: 5.9396e-14\n",
      "Epoch180 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5665 - d: 4.2125e-14\n",
      "Epoch181 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.6181 - d: 4.2687e-14\n",
      "Epoch182 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8909 - d: 3.8354e-14\n",
      "Epoch183 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.9781 - d: 2.9692e-14\n",
      "Epoch184 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2713 - d: 3.0620e-14\n",
      "Epoch185 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.8491 - d: 2.0770e-14\n",
      "Epoch186 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0307 - d: 1.9947e-14- ETA: 1s - g\n",
      "Epoch187 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5280 - d: 1.9285e-14\n",
      "Epoch188 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0044 - d: 1.9954e-14\n",
      "Epoch189 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0570 - d: 1.9026e-14\n",
      "Epoch190 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2863 - d: 1.5920e-14\n",
      "Epoch191 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.1834 - d: 1.1227e-14\n",
      "Epoch192 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.9867 - d: 1.5276e-14\n",
      "Epoch193 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0088 - d: 1.4107e-14\n",
      "Epoch194 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3288 - d: 1.3901e-14\n",
      "Epoch195 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3117 - d: 1.1347e-14\n",
      "Epoch196 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.0295 - d: 8.9213e-15\n",
      "Epoch197 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.9529 - d: 1.1055e-14\n",
      "Epoch198 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5732 - d: 1.0246e-14\n",
      "Epoch199 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4671 - d: 8.4923e-15\n",
      "Epoch200 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6330 - d: 9.5351e-15- ETA: 0s - g: 36.6588 - d: 9.5135e-1\n",
      "Epoch201 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6627 - d: 9.0178e-15\n",
      "Epoch202 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6587 - d: 7.7855e-15\n",
      "Epoch203 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.9358 - d: 8.8338e-15\n",
      "Epoch204 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.0067 - d: 7.4654e-15\n",
      "Epoch205 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4236 - d: 7.5084e-15\n",
      "Epoch206 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4909 - d: 8.6696e-15\n",
      "Epoch207 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7175 - d: 8.1393e-15\n",
      "Epoch208 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.2288 - d: 6.1831e-15\n",
      "Epoch209 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.2334 - d: 8.5788e-15\n",
      "Epoch210 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.3579 - d: 5.8624e-15\n",
      "Epoch211 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0349 - d: 7.5490e-15- ETA: 0s - g: 36.0630 - d: 7.6\n",
      "Epoch212 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5118 - d: 6.2608e-15\n",
      "Epoch213 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1427 - d: 6.9923e-15\n",
      "Epoch214 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 36.4962 - d: 6.3154e-15\n",
      "Epoch215 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1609 - d: 6.1528e-15\n",
      "Epoch216 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5286 - d: 6.0716e-15\n",
      "Epoch217 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.8033 - d: 5.2017e-15\n",
      "Epoch218 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3035 - d: 5.9241e-15\n",
      "Epoch219 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1473 - d: 6.7257e-15\n",
      "Epoch220 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6250 - d: 5.3037e-15\n",
      "Epoch221 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4257 - d: 5.7011e-15\n",
      "Epoch222 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1704 - d: 5.5201e-15\n",
      "Epoch223 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6353 - d: 5.4376e-15\n",
      "Epoch224 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.8005 - d: 5.1136e-15\n",
      "Epoch225 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.5215 - d: 5.9284e-15\n",
      "Epoch226 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 37.1222 - d: 4.8998e-15\n",
      "Epoch227 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.6366 - d: 6.3023e-15\n",
      "Epoch228 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6486 - d: 5.6296e-15\n",
      "Epoch229 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3567 - d: 4.5743e-15\n",
      "Epoch230 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2729 - d: 5.2721e-15\n",
      "Epoch231 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1518 - d: 5.6077e-15\n",
      "Epoch232 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8285 - d: 5.1334e-15\n",
      "Epoch233 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3365 - d: 5.0234e-15\n",
      "Epoch234 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4676 - d: 3.9560e-15\n",
      "Epoch235 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2416 - d: 4.7039e-15\n",
      "Epoch236 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6919 - d: 5.0173e-15\n",
      "Epoch237 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2547 - d: 4.0258e-15\n",
      "Epoch238 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5174 - d: 4.5443e-15\n",
      "Epoch239 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7995 - d: 4.9530e-15\n",
      "Epoch240 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0110 - d: 5.2942e-15\n",
      "Epoch241 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2468 - d: 5.2405e-15\n",
      "Epoch242 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.6724 - d: 5.1232e-15\n",
      "Epoch243 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4279 - d: 5.2287e-15\n",
      "Epoch244 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.4635 - d: 6.0761e-15\n",
      "Epoch245 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4400 - d: 6.0477e-15\n",
      "Epoch246 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0664 - d: 7.3371e-15\n",
      "Epoch247 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.3769 - d: 8.8630e-15\n",
      "Epoch248 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.6089 - d: 1.1247e-14\n",
      "Epoch249 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8063 - d: 2.5980e-14\n",
      "Epoch250 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0096 - d: 4.7119e-14\n",
      "Epoch251 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.8908 - d: 8.1520e-14\n",
      "Epoch252 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.2542 - d: 8.4135e-14\n",
      "Epoch253 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.7140 - d: 7.9220e-14\n",
      "Epoch254 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.7619 - d: 6.4230e-14\n",
      "Epoch255 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7595 - d: 4.0630e-14\n",
      "Epoch256 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 34.9898 - d: 4.9210e-14\n",
      "Epoch257 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.5289 - d: 3.5787e-14- ETA: 0s - g: 35.5984 - d: 3.3707e - ETA: 0s - g: 35.4973 - d: 3.6457e-14\n",
      "Epoch258 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7990 - d: 3.4818e-14\n",
      "Epoch259 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.6023 - d: 3.7841e-1 - ETA: 0s - g: 35.6011 - d: 3.7663e-14\n",
      "Epoch260 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.3837 - d: 3.4453e-14\n",
      "Epoch261 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0577 - d: 2.8429e-14\n",
      "Epoch262 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0550 - d: 2.1141e-14\n",
      "Epoch263 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 36.0104 - d: 2.3035e-14\n",
      "Epoch264 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.7160 - d: 2.0538e-14\n",
      "Epoch265 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3547 - d: 1.6227e-14\n",
      "Epoch266 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.5242 - d: 2.2106e-14\n",
      "Epoch267 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1243 - d: 1.5756e-14\n",
      "Epoch268 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.6269 - d: 2.3463e-14\n",
      "Epoch269 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3706 - d: 1.3166e-14\n",
      "Epoch270 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1493 - d: 1.4707e-14- ETA: 8s - g: 36.0711 \n",
      "Epoch271 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 36.4112 - d: 1.1138e-14\n",
      "Epoch272 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.9539 - d: 1.5241e-14\n",
      "Epoch273 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.4924 - d: 1.0613e-14\n",
      "Epoch274 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0217 - d: 1.2028e-14-\n",
      "Epoch275 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6786 - d: 9.6090e-15\n",
      "Epoch276 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1315 - d: 1.1733e-14\n",
      "Epoch277 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.0563 - d: 1.0893e-14\n",
      "Epoch278 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.9091 - d: 9.2137e-15\n",
      "Epoch279 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2142 - d: 1.0525e-14\n",
      "Epoch280 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3413 - d: 9.3717e-15\n",
      "Epoch281 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.1501 - d: 1.0036e-14\n",
      "Epoch282 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.9289 - d: 6.4545e-15\n",
      "Epoch283 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 36.5482 - d: 9.4660e-15\n",
      "Epoch284 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5142 - d: 8.3962e-15\n",
      "Epoch285 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2629 - d: 9.7254e-15\n",
      "Epoch286 end\n",
      "419/421 [============================>.] - ETA: 0s - g: 36.7558 - d: 8.2242e-15\n",
      "Epoch287 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 35.8671 - d: 1.0659e-14\n",
      "Epoch288 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.8288 - d: 6.8063e-15\n",
      "Epoch289 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3550 - d: 8.5214e-15\n",
      "Epoch290 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2386 - d: 8.2769e-15\n",
      "Epoch291 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2863 - d: 8.5085e-15\n",
      "Epoch292 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.6436 - d: 7.4321e-15\n",
      "Epoch293 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3682 - d: 7.5812e-15\n",
      "Epoch294 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5316 - d: 7.4357e-15\n",
      "Epoch295 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.5420 - d: 7.5520e-15\n",
      "Epoch296 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.2841 - d: 7.0998e-15\n",
      "Epoch297 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3120 - d: 7.4011e-15\n",
      "Epoch298 end\n",
      "420/421 [============================>.] - ETA: 0s - g: 36.3165 - d: 7.9809e-15- ET - ETA: 2\n",
      "Epoch299 end\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    batch_size = BATCH\n",
    "    epochs = EPOCH\n",
    "    input_dim = DIM\n",
    "    g_optim = Adam(lr=LR, beta_1=0.5, beta_2=0.999)\n",
    "    d_optim = Adam(lr=LR, beta_1=0.5, beta_2=0.999)\n",
    "  \n",
    "    # データセットの読み込み\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    #(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()  # Fashion MNIST \n",
    "    \n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "  \n",
    "    # 学習データの作成\n",
    "    x_train_1 = []\n",
    "    for i in range(len(x_train)):\n",
    "        if y_train[i] == 1: \n",
    "           x_train_1.append(x_train[i].reshape((28, 28, 1))) \n",
    "    x_train_1 = np.array(x_train_1)\n",
    "    print(\"train data:\",len(x_train_1))\n",
    "  \n",
    "    # 評価データの作成\n",
    "    cnt = 0\n",
    "    x_test_9, y = [], []\n",
    "    for i in range(len(x_test)):\n",
    "        if y_test[i] == 1 or y_test[i] == 9:  \n",
    "           x_test_9.append(x_test[i].reshape((28, 28, 1))) \n",
    "           y.append(y_test[i])\n",
    "           cnt +=1\n",
    "           if cnt == 100:\n",
    "              break           \n",
    "    x_test_9 = np.array(x_test_9)\n",
    "    print(\"test_data:\",len(x_test_9))    \n",
    "    input_shape = x_train_1[0].shape   \n",
    "    X_test_original = x_test_9.copy()    \n",
    " \n",
    "   \n",
    "    # train generator & discriminator\n",
    "    dcgan = DCGAN(input_dim, input_shape)\n",
    "    dcgan.compile(g_optim, d_optim)\n",
    "    g_losses, d_losses = dcgan.train(epochs, batch_size, x_train_1)  \n",
    "    with open('loss.csv', 'w') as f:\n",
    "        for g_loss, d_loss in zip(g_losses, d_losses):\n",
    "            f.write(str(g_loss) + ',' + str(d_loss) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(X):\n",
    "    return ((X + 1.0)/2.0*255.0).astype(dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 41.93\n",
      "1 57.37\n",
      "2 85.13\n",
      "3 124.99\n",
      "4 92.21\n",
      "5 66.63\n",
      "6 92.39\n",
      "7 110.31\n",
      "8 53.33\n",
      "9 45.69\n",
      "10 56.95\n",
      "11 74.76\n",
      "12 30.14\n",
      "13 77.89\n",
      "14 43.42\n",
      "15 105.87\n",
      "16 56.82\n",
      "17 117.93\n",
      "18 61.84\n",
      "19 82.68\n",
      "20 69.33\n",
      "21 60.14\n",
      "22 93.03\n",
      "23 49.40\n",
      "24 122.29\n",
      "25 88.15\n",
      "26 82.63\n",
      "27 57.63\n",
      "28 91.85\n",
      "29 93.43\n",
      "30 69.06\n",
      "31 76.95\n",
      "32 72.58\n",
      "33 82.40\n",
      "34 48.28\n",
      "35 45.75\n",
      "36 94.00\n",
      "37 122.06\n",
      "38 41.90\n",
      "39 59.09\n",
      "40 33.70\n",
      "41 55.45\n",
      "42 50.46\n",
      "43 91.48\n",
      "44 39.01\n",
      "45 86.90\n",
      "46 53.67\n",
      "47 85.19\n",
      "48 77.36\n",
      "49 51.89\n",
      "50 37.53\n",
      "51 43.18\n",
      "52 113.57\n",
      "53 124.68\n",
      "54 122.01\n",
      "55 123.17\n",
      "56 30.33\n",
      "57 51.51\n",
      "58 75.16\n",
      "59 49.24\n",
      "60 118.33\n",
      "61 39.12\n",
      "62 117.97\n",
      "63 77.02\n",
      "64 72.20\n",
      "65 69.73\n",
      "66 48.69\n",
      "67 112.87\n",
      "68 128.55\n",
      "69 64.48\n",
      "70 40.04\n",
      "71 105.01\n",
      "72 88.84\n",
      "73 64.86\n",
      "74 112.27\n",
      "75 52.67\n",
      "76 61.20\n",
      "77 124.09\n",
      "78 66.31\n",
      "79 102.25\n",
      "80 65.72\n",
      "81 53.78\n",
      "82 55.30\n",
      "83 113.55\n",
      "84 56.65\n",
      "85 72.47\n",
      "86 60.53\n",
      "87 72.36\n",
      "88 51.54\n",
      "89 32.95\n",
      "90 114.73\n",
      "91 43.82\n",
      "92 45.54\n",
      "93 39.81\n",
      "94 49.39\n",
      "95 101.86\n",
      "96 51.28\n",
      "97 66.83\n",
      "98 62.45\n",
      "99 77.59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcYklEQVR4nO3de7QdZZ3m8e9jEoyQTHPJASEXEnohCowgxgDag6iAkAZhxl6ajBcQlgEbWphxrQaxxx67xx6mu7UbBWXCRbzQAS9EAwYBaRnEBkPAgMGARARyTCQX7gJK8Jk/qk6zPbw7OUnOvpx9ns9ae+2qt9569+89t9+pt+qtkm0iIiIGe0WnA4iIiO6UBBEREUVJEBERUZQEERERRUkQERFRlAQRERFFSRAxIkm6V9LhnY6j1ST9L0nrJf2607HE6JMEEV1H0kOSjhhUdpKkWwfWbe9n++bNtDNdkiWNbVGoLSVpKvAxYF/br25S51xJv5T0jKR+SVe1N8roZUkQEU2o0snfkT2BDbbXljZKOhH4AHCE7QnATOCm4QxgpCbXGB5JEDEiNR5lSJolaamkpyQ9KumzdbVb6vcn6v+wD5U0RtJn6mGbX0o6o/EoQ9LNkj4t6UfAs8Bekj4kaYWkpyU9KOnUhjgOr/9z/0tJayWtkXSCpNmSfi7pMUnnbqIffyTpK5LWSXpY0l9JekXdtxuBPerYLy/s/ibgetu/ALD9a9vzG9reWdKXJK2W9Likbzds+7CklXV8iyTt0bDNkk6X9ADwQF12rKRlkp6Q9G+SXj/kb1aMWPnvIHrB+cD5tr8qaQKwf11+GPBLYEfbGwEknQYcAxwI/Ab4RqG9D9R17gcE7AMcCzxYt3mdpDts31XXfzUwHpgMnARcTPXH/Y3ANOBOSVfafrDwWZ8H/gjYC9gFuAFYY/tSSccAX7M9pUm/bwc+J+lXwA+An9h+sWH7V4FngP3q9zfXX4O3A/8bOAq4F/hH4Mq6bwNOAA4GnpN0EHAZcBywFHg/sEjSPrZ/2yS26AW288qrq17AQ1R/0J5oeD0L3DqozhH18i3Ap4BJg9qZDhgY21D2r8CpDetHNNYBbgb+ZjPxfRs4s14+HHgOGFOvT6zbO7ih/p3ACYV2xgC/pTrHMFB2KnBzQ9v9m4nlfcD3qZLdBuCcunx34PfAToV9LgX+vmF9AvACML1eN/D2hu1fBP52UBv3A2/t9M9KXq19ZYgputUJtncceAF/vom6pwCvAe6TdIekYzdRdw9gVcP6qkKdPyiTdIyk2+vhmCeA2cCkhiob/NJ/7s/V7482bH+O6o/wYJOA7YCHG8oepjoSGRLbV9g+AtgROA34G0nvBKYCj9l+vLDbHo2fafsZquTS+LmNX4M9gY/Vw0tP1F+DqXU70cOSIGLEs/2A7bnArsD/Ab4paQeq/4QHWwM0DtlMLTU5sCDplcC3qIZhdquT1WKqoadttZ7qP/c9G8qmAb/a0oZsv2D7G8A9VENsq4CdJe1YqL668TPrr9Uugz638Wu3Cvh0Y8K2vb3tBVsaZ4wsSRAx4kl6v6Q+27+nGo4CeBFYRzXMsldD9a8DZ0qaXP/xPHszzW8HvLJua2N9XuCo4Yi7Pur4OvBpSRMl7Qn8d+BrQ9m/vvT3T+t9X1HHth/wY9trgOuAL0jaSdI4SQPnGP4F+JCkA+sE+Hf1Pg81+aiLgdMkHVxf2bXDwOdudedjREiCiF5wNHCvpGeoTljPsf287WeBTwM/qodGDqH6Y3cD1X/aP6E6GthIlVBexvbTwEep/pA/DvxXYNEwxv4XVOcPHgRupfrjfdkQ930KOBd4hCox/j3wEdsD80U+QHWEch+wFjgLwPZNwP+gOjJaA/wxMKfZh9heCnwYuIDqa7CS6mR89DjZeWBQjF71f90X2d5zs5UjRpkcQcSoIulV9RyFsZImA38NLOx0XBHdKEcQMapI2h74f8Brqa4u+i7VJatPdTSwiC6UBBEREUUZYoqIiKKeutXGpEmTPH369E6HERExYtx5553rbfeVtvVUgpg+fTpLly7tdBgRESOGpIebbcsQU0REFCVBREREURJEREQU9dQ5iIiITnjhhRfo7+/n+eef73QoTY0fP54pU6Ywbty4Ie+TBBERsY36+/uZOHEi06dPRxqOG/0OL9ts2LCB/v5+ZsyYMeT9MsQUEbGNnn/+eXbZZZeuTA4Akthll122+AgnCSIiYhh0a3IYsDXxJUFERERRzkFERAy3a64Z3vaOO26zVU4++WSuvfZadt11V5YvXz4sH5sE0QmlH54h/ABERDRz0kknccYZZ/DBD35w2NrMEFNERA847LDD2HnnnYe1zSSIiIgoSoKIiIiiJIiIiChKgoiIiKKWXcUkaSrwFeDVwO+B+bbPl7QzcBUwHXgIeI/txwv7Hw2cD4wBLrF9XqtijYgYVh24KnHu3LncfPPNrF+/nilTpvCpT32KU045ZZvabOVlrhuBj9m+S9JE4E5JNwInATfZPk/SOcA5wNmNO0oaA1wIHAn0A3dIWmT7Zy2MNyJixFqwYMGwt9myISbba2zfVS8/DawAJgPHA1+uq30ZOKGw+yxgpe0Hbf8OuLLeLyIi2qQt5yAkTQfeAPwY2M32GqiSCLBrYZfJwKqG9f66LCIi2qTlCULSBOBbwFm2nxrqboUyN2l/nqSlkpauW7dua8OMiIhBWpogJI2jSg5X2L66Ln5U0u719t2BtYVd+4GpDetTgNWlz7A93/ZM2zP7+vqGL/iIiFGuZQlC1b1lLwVW2P5sw6ZFwIn18onAdwq73wHsLWmGpO2AOfV+ERHRJq08gngL8AHg7ZKW1a/ZwHnAkZIeoLpK6TwASXtIWgxgeyNwBnA91cntr9u+t4WxRkTEIC27zNX2rZTPJQC8o1B/NTC7YX0xsLg10UVEtE4H7vYNwPnnn8/FF1+MbT784Q9z1llnbdPnZiZ1REQPWL58ORdffDFLlizh7rvv5tprr+WBBx7YpjaTICIiesCKFSs45JBD2H777Rk7dixvfetbWbhw4Ta1mQQREdED9t9/f2655RY2bNjAs88+y+LFi1m1atXmd9yEPFEuIqIHvO51r+Pss8/myCOPZMKECRxwwAGMHbttf+KTILZGHhkaEV3olFNO+fcb9J177rlMmTJlm9pLgoiI6BFr165l11135ZFHHuHqq6/mtttu26b2kiAiIoZZpwYU3v3ud7NhwwbGjRvHhRdeyE477bRN7SVBRET0iB/+8IfD2l6uYoqIiKIkiIiIKEqCiIgYBnbxiQRdY2viS4KIiNhG48ePZ8OGDV2bJGyzYcMGxo8fv0X75SR1RMQ2mjJlCv39/XTzQ8vGjx+/xfMikiAiIrbRuHHjmDFjRqfDGHZJEMOl2f19M8M6IkaonIOIiIiilh1BSLoMOBZYa3v/uuwqYJ+6yo7AE7YPLOz7EPA08CKw0fbMVsUZERFlrRxiuhy4APjKQIHt9w4sS/oM8OQm9n+b7fUtiy4iIjaplY8cvUXS9NI2SQLeA7y9VZ8fERHbplPnIP4T8KjtZs/DM3CDpDslzdtUQ5LmSVoqaWk3X2IWETHSdCpBzAUWbGL7W2wfBBwDnC7psGYVbc+3PdP2zL6+vuGOMyJi1Gp7gpA0FvgvwFXN6theXb+vBRYCs9oTXUREDOjEEcQRwH22+0sbJe0gaeLAMnAUsLyN8UVEBC1MEJIWALcB+0jql3RKvWkOg4aXJO0haXG9uhtwq6S7gSXAd21/r1VxRkREWSuvYprbpPykQtlqYHa9/CBwQKviioiIoclM6oiIKEqCiIiIoiSIiIgoSoKIiIiiJIiIiChKgoiIiKIkiIiIKEqCiIiIoiSIiIgoSoKIiIiiJIiIiChKgoiIiKIkiIiIKEqCiIiIoiSIiIgoSoKIiIiiVj5R7jJJayUtbyj7n5J+JWlZ/ZrdZN+jJd0vaaWkc1oVY0RENNfKI4jLgaML5f9k+8D6tXjwRkljgAuBY4B9gbmS9m1hnBERUdCyBGH7FuCxrdh1FrDS9oO2fwdcCRw/rMFFRMRmdeIcxBmS7qmHoHYqbJ8MrGpY76/LiiTNk7RU0tJ169YNd6wREaNWuxPEF4E/Bg4E1gCfKdRRoczNGrQ93/ZM2zP7+vqGJciIiGhzgrD9qO0Xbf8euJhqOGmwfmBqw/oUYHU74ouIiJe0NUFI2r1h9T8DywvV7gD2ljRD0nbAHGBRO+KLiIiXjG1Vw5IWAIcDkyT1A38NHC7pQKoho4eAU+u6ewCX2J5te6OkM4DrgTHAZbbvbVWcERFR1rIEYXtuofjSJnVXA7Mb1hcDL7sENiIi2iczqSMioigJIiIiipIgIiKiKAkiIiKKkiAiIqIoCSIiIoqSICIioigJIiIiipIgIiKiKAkiIiKKkiAiIqIoCSIiIoqSICIioigJIiIiilp2u++oXXNNpyOIiNgqLTuCkHSZpLWSljeU/YOk+yTdI2mhpB2b7PuQpJ9KWiZpaatijIiI5lo5xHQ5cPSgshuB/W2/Hvg58PFN7P822wfantmi+CIiYhNaliBs3wI8NqjsBtsb69XbgSmt+vyIiNg2nTxJfTJwXZNtBm6QdKekeW2MKSIiah05SS3pE8BG4IomVd5ie7WkXYEbJd1XH5GU2poHzAOYNm1aS+KNiBiN2n4EIelE4FjgfbZdqmN7df2+FlgIzGrWnu35tmfantnX19eKkCMiRqW2JghJRwNnA++y/WyTOjtImjiwDBwFLC/VjYiI1mnlZa4LgNuAfST1SzoFuACYSDVstEzSRXXdPSQtrnfdDbhV0t3AEuC7tr/XqjgjIqKsZecgbM8tFF/apO5qYHa9/CBwQKviioiIocmtNiIioigJIiIiijY7xCRp501tt/3YprZHRMTINJRzEHcBU4HHAQE7Ao/U2wzs1ZLIIiKio4YyxPQ94Djbk2zvQjWH4WrbM2wnOURE9KihJIg32R64BBXb1wFvbV1IERHRDYYyxLRe0l8BX6MaUno/sKGlUUVERMcN5QhiLtBHdcuLhfVyaY5DRET0kM0eQdRXKZ0paYLtZ9oQU0REdIGhXOb6ZuASYAIwTdIBwKm2/7zVwbVV6dGgxx3X/jgiIrrEUIaY/gl4J/V5B9t3A4e1MqiIiOi8Ic2ktr1qUNGLLYglIiK6yFCuYlpVDzNZ0nbAR4EVrQ0rIiI6bShHEKcBpwOTgX7gwHo9IiJ62CaPICSNAf7Z9vvaFE9ERHSJTR5B2H4R6KuHliIiYhQZyjmIh4AfSVoE/Gag0PZnN7WTpMuo7tu01vb+ddnOwFXA9Lrd99h+vLDv0cD5wBjgEtvnDSHOiIgYRk2PICR9tV58L3BtXXdiw2tzLgeOHlR2DnCT7b2Bm+r1wZ87BrgQOAbYF5grad8hfF5ERAyjTR1BvFHSnlS39v78ljZs+xZJ0wcVHw8cXi9/GbgZOHtQnVnAyvrRo0i6st7vZ1saQ0REbL1NJYiLqG71PQNY2lAutv45ELvZXgNge42kXQt1JgON8y76gYObNShpHjAPYNq0aVsRUpcozeSGzOaOES8/2iNX0yEm25+z/TrgS7b3ani1+jkQKoXTrLLt+bZn2p7Z19fXwrAiIkaXzc6DsP2RYfy8RyXtDlC/ry3U6ad6gt2AKcDqYYwhIiKGYEi32hhGi4AT6+UTge8U6twB7C1pRn157Zx6v4iIaKOWJQhJC4DbgH0k9Us6BTgPOFLSA8CR9TqS9pC0GMD2RuAM4HqqW3p83fa9rYozIiLKhjIPYqvYbvZQoXcU6q4GZjesLwYWD64XERHt0+4hpoiIGCGSICIioigJIiIiipIgIiKiqGUnqXtCsymgEW02HLORt7SNzICOHEFERERREkRERBQlQURERFESREREFCVBREREURJEREQUJUFERERREkRERBQlQURERFFmUsfIVZrqm2m+EcMmRxAREVHU9gQhaR9JyxpeT0k6a1CdwyU92VDnk+2OMyJitGv7EJPt+4EDASSNAX4FLCxU/aHtY9sYWkRENOj0ENM7gF/YfrjDcURExCCdThBzgAVNth0q6W5J10nar1kDkuZJWipp6bp161oTZUTEKNSxBCFpO+BdwDcKm+8C9rR9APB54NvN2rE93/ZM2zP7+vpaEmtExGjUySOIY4C7bD86eIPtp2w/Uy8vBsZJmtTuACMiRrNOJoi5NBlekvRqSaqXZ1HFuaGNsUVEjHodmSgnaXvgSODUhrLTAGxfBPwZ8BFJG4HngDm23YlYIyJGq44kCNvPArsMKruoYfkC4IJ2xxXRLnnec+vla7ztOn0VU0REdKkkiIiIKEqCiIiIoiSIiIgoSoKIiIiiJIiIiChKgoiIiKIkiIiIKEqCiIiIojyTutdlOmlEbKUcQURERFESREREFCVBREREURJEREQUJUFERERRRxKEpIck/VTSMklLC9sl6XOSVkq6R9JBnYgzImI06+Rlrm+zvb7JtmOAvevXwcAX6/eIiGiTbh1iOh74iiu3AztK2r3TQUVEjCadOoIwcIMkA//X9vxB2ycDqxrW++uyNYMbkjQPmAcwbdq01kQbQ9PGSXnXXAMs2e3lH0V3TQxs9iVpZfuZA9k5vTYvtVNHEG+xfRDVUNLpkg4btF2FfVxqyPZ82zNtz+zr6xvuOCMiRq2OJAjbq+v3tcBCYNagKv3A1Ib1KcDq9kQXERHQgQQhaQdJEweWgaOA5YOqLQI+WF/NdAjwpO2XDS9FRETrdOIcxG7AQkkDn/8vtr8n6TQA2xcBi4HZwErgWeBDHYgzImJUa3uCsP0gcECh/KKGZQOntzOuiIj4Q916mWtERHRYEkRERBQlQURERFESREREFOWRozF6des05FJcS3aDWYOnCw1993bo1c9t5ezobp95nSOIiIgoSoKIiIiiJIiIiChKgoiIiKIkiIiIKEqCiIiIoiSIiIgoSoKIiIiiJIiIiCjKTOqRaDimX3Z6FvGWTH8dhriKH7dkN46b9ejWN9DGZ213k07NmO42rfw6dMsM6xxBREREUSceOTpV0g8krZB0r6QzC3UOl/SkpGX165PtjjMiYrTrxBDTRuBjtu+qn019p6Qbbf9sUL0f2j62A/FFRAQdOIKwvcb2XfXy08AKYHK744iIiE3r6DkISdOBNwA/Lmw+VNLdkq6TtN8m2pgnaamkpevWrWtVqBERo07HEoSkCcC3gLNsPzVo813AnrYPAD4PfLtZO7bn255pe2ZfX1/L4o2IGG06kiAkjaNKDlfYvnrwdttP2X6mXl4MjJM0qc1hRkSMap24iknApcAK259tUufVdT0kzaKKc0P7ooyIiE5cxfQW4APATyUtq8vOBaYB2L4I+DPgI5I2As8Bc2y7A7FGRIxabU8Qtm8FtJk6FwAXtCeiLtfOaav1Z10zeCZv/SzkrZ7FuQ19uGbJbrBkyZbVLyq38bL6TT+r0G5D3aYzsgfab/Y86S3o25D3H+Kzq0erzAQfusykjoiIoiSIiIgoSoKIiIiiJIiIiChKgoiIiKIkiIiIKEqCiIiIoiSIiIgoSoKIiIiiPJM6tk6mo26ZbZ0xPVxtFNq8ZqjNbskM7WaxNrSxpc9dzo9c+59VnSOIiIgoSoKIiIiiJIiIiChKgoiIiKIkiIiIKEqCiIiIok49k/poSfdLWinpnMJ2Sfpcvf0eSQd1Is6IiNGsE8+kHgNcCBwD7AvMlbTvoGrHAHvXr3nAF9saZEREdOQIYhaw0vaDtn8HXAkcP6jO8cBXXLkd2FHS7u0ONCJiNOvETOrJwKqG9X7g4CHUmQysGdyYpHlURxkAz0i6H5gErB+ugDuoF/rRC32A3uhHL/QBeqMf3dSHPZtt6ESCUKHMW1GnKrTnA/P/YGdpqe2ZWxde9+iFfvRCH6A3+tELfYDe6MdI6UMnhpj6gakN61OA1VtRJyIiWqgTCeIOYG9JMyRtB8wBFg2qswj4YH010yHAk7ZfNrwUERGt0/YhJtsbJZ0BXA+MAS6zfa+k0+rtFwGLgdnASuBZ4ENb+DHzN19lROiFfvRCH6A3+tELfYDe6MeI6IPs4tB+RESMcplJHRERRUkQERFR1HMJYnO38ehGkqZK+oGkFZLulXRmXb6zpBslPVC/79TpWDdH0hhJP5F0bb0+Evuwo6RvSrqv/p4cOkL78d/qn6flkhZIGt/t/ZB0maS1kpY3lDWNWdLH69/1+yW9szNRv1yTfvxD/TN1j6SFknZs2NaV/eipBDHE23h0o43Ax2y/DjgEOL2O+xzgJtt7AzfV693uTGBFw/pI7MP5wPdsvxY4gKo/I6ofkiYDHwVm2t6f6oKQOXR/Py4Hjh5UVoy5/h2ZA+xX7/OF+m9AN7icl/fjRmB/268Hfg58HLq7Hz2VIBjabTy6ju01tu+ql5+m+oM0mSr2L9fVvgyc0JEAh0jSFOBPgUsaikdaH/4DcBhwKYDt39l+ghHWj9pY4FWSxgLbU80l6up+2L4FeGxQcbOYjweutP1b27+kuupxCx6c3Tqlfti+wfbGevV2qvld0MX96LUE0ewWHSOGpOnAG4AfA7sNzP+o33ftYGhD8c/AXwK/bygbaX3YC1gHfKkeKrtE0g6MsH7Y/hXwj8AjVLeoedL2DYywftSaxTySf99PBq6rl7u2H72WIIZ8i45uJGkC8C3gLNtPdTqeLSHpWGCt7Ts7Hcs2GgscBHzR9huA39B9wzCbVY/THw/MAPYAdpD0/s5GNexG5O+7pE9QDStfMVBUqNYV/ei1BDFib9EhaRxVcrjC9tV18aMDd7Gt39d2Kr4heAvwLkkPUQ3tvV3S1xhZfYDqZ6jf9o/r9W9SJYyR1o8jgF/aXmf7BeBq4M2MvH5A85hH3O+7pBOBY4H3+aVJaF3bj15LEEO5jUfXkSSqMe8Vtj/bsGkRcGK9fCLwnXbHNlS2P257iu3pVF/3f7X9fkZQHwBs/xpYJWmfuugdwM8YYf2gGlo6RNL29c/XO6jObY20fkDzmBcBcyS9UtIMqufHLOlAfEMi6WjgbOBdtp9t2NS9/bDdUy+qW3T8HPgF8IlOxzPEmP+E6pDyHmBZ/ZoN7EJ11cYD9fvOnY51iP05HLi2Xh5xfQAOBJbW349vAzuN0H58CrgPWA58FXhlt/cDWEB1zuQFqv+sT9lUzMAn6t/1+4FjOh3/Zvqxkupcw8Dv+EXd3o/caiMiIop6bYgpIiKGSRJEREQUJUFERERREkRERBQlQURERFESRMRWkPSJ+k6p90haJungTscUMdza/sjRiJFO0qFUs2EPsv1bSZOA7bahvbF+6SZuEV0jRxARW253YL3t3wLYXm97taQ3Sfo3SXdLWiJpYv0Mhi9J+ml987+3AUg6SdI3JF0D3CBph/oZAnfU9br+LsTR+3IEEbHlbgA+KennwPeBq4Db6vf32r6jvm34c1TPx8D2f5T0Wqpk8Jq6nUOB19t+TNLfUd2e5OT6QTJLJH3f9m/a27WIl+QIImIL2X4GeCMwj+rW4FcBpwJrbN9R13mqHjb6E6rbXGD7PuBhYCBB3Gh74JkBRwHnSFoG3AyMB6a1oz8RzeQIImIr2H6R6g/5zZJ+CpxO+RbNpVs5D2g8OhDwbtv3D1uQEdsoRxARW0jSPpL2big6kOpOqXtIelNdZ2L9JLdbgPfVZa+hOiooJYHrgb+o77yKpDe0rgcRQ5MjiIgtNwH4fH2uYCPVXTrnAV+qy19Fdf7hCOALwEX1UcZG4KT6yqfBbf4t1RP57qmTxENUV0pFdEzu5hoREUUZYoqIiKIkiIiIKEqCiIiIoiSIiIgoSoKIiIiiJIiIiChKgoiIiKL/D2UjhsezXdIHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    iterations = 100\n",
    "    input_dim = 30\n",
    "    anogan_optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    " \n",
    "    # load weights\n",
    "    dcgan = DCGAN(input_dim, input_shape)\n",
    "    dcgan.load_weights('weights/generator_99.h5', 'weights/discriminator_99.h5')  #3999.99\n",
    " \n",
    "    for i, test_img in enumerate(x_test_9):  \n",
    "        test_img = test_img[np.newaxis,:,:,:]\n",
    "        anogan = ANOGAN(input_dim, dcgan.g)\n",
    "        anogan.compile(anogan_optim)\n",
    "        anomaly_score, generated_img = anogan.compute_anomaly_score(test_img, iterations)\n",
    " \n",
    "        generated_img = denormalize(generated_img)\n",
    "        imgs = np.concatenate((denormalize(test_img[0]), generated_img[0]), axis=1)\n",
    "        cv2.imwrite('predict' + os.sep + str(int(anomaly_score)) + '_' + str(i) + '.png', imgs)\n",
    "        print(str(i) + ' %.2f'%anomaly_score)\n",
    " \n",
    "        if y[i] == 1 :       \n",
    "           with open('scores_1.txt', 'a') as f:\n",
    "                f.write(str(anomaly_score) + '\\n')\n",
    "        else:\n",
    "           with open('scores_9.txt', 'a') as f:\n",
    "                f.write(str(anomaly_score) + '\\n') \n",
    "    \n",
    "    # plot histgram\n",
    "    import matplotlib.pyplot as plt\n",
    "    import csv\n",
    "    \n",
    "    x =[]\n",
    "    with open('scores_1.txt', 'r') as f:\n",
    "         reader = csv.reader(f)\n",
    "         for row in reader:\n",
    "             row = int(float(row[0]))\n",
    "             x.append(row)\n",
    "    y =[]\n",
    "    with open('scores_9.txt', 'r') as f:\n",
    "         reader = csv.reader(f)\n",
    "         for row in reader:\n",
    "             row = int(float(row[0]))\n",
    "             y.append(row)\n",
    "             \n",
    "    plt.title(\"Histgram of Score\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.ylabel(\"freq\")\n",
    "    plt.hist(x, bins=40, alpha=0.3, histtype='stepfilled', color='r', label=\"1\")\n",
    "    plt.hist(y, bins=40, alpha=0.3, histtype='stepfilled', color='b', label='9')\n",
    "    plt.legend(loc=1)\n",
    "    plt.savefig(\"histgram.png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

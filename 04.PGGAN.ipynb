{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tzmi.hatenablog.com/entry/2020/05/07/230232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a864a678029d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PixelNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def forward(self, x):\n",
    "        eps = 1e-7\n",
    "        mean = torch.mean(x**2, dim=1, keepdims=True)\n",
    "        return x / (torch.sqrt(mean)+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重みの標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightScale(nn.Module):\n",
    "    def forward(self, x, gain=2):\n",
    "        scale = (gain/x.shape[1])**0.5\n",
    "        return x * scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniBatch 処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchStd(nn.Module):\n",
    "    def forward(self, x):\n",
    "        std = torch.std(x, dim=0, keepdim=True)\n",
    "        mean = torch.mean(std, dim=(1,2,3), keepdim=True)\n",
    "        n,c,h,w = x.shape\n",
    "        mean = torch.ones(n,1,h,w, dtype=x.dtype, device=x.device)*mean\n",
    "        return torch.cat((x,mean), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2次元の Convolutional モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, inch, outch, kernel_size, padding=0):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            WeightScale(),\n",
    "            nn.ReflectionPad2d(padding),\n",
    "            nn.Conv2d(inch, outch, kernel_size, padding=0),\n",
    "            PixelNorm(),\n",
    "            )\n",
    "        nn.init.kaiming_normal_(self.layers[2].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional for Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModuleG(nn.Module):\n",
    "    '''\n",
    "    Args:\n",
    "        out_size: (int), Ex.: 16 (resolution)\n",
    "        inch: (int),  Ex.: 256\n",
    "        outch: (int), Ex.: 128\n",
    "    '''\n",
    "    def __init__(self, out_size, inch, outch, first=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if first:\n",
    "            layers = [\n",
    "                Conv2d(inch, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "                Conv2d(outch, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            layers = [\n",
    "                nn.Upsample((out_size, out_size), mode='nearest'),\n",
    "                Conv2d(inch, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "                Conv2d(outch, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "            ]\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Module for Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModuleD(nn.Module):\n",
    "    '''\n",
    "    Args:\n",
    "        out_size: (int), Ex.: 16 (resolution)\n",
    "        inch: (int),  Ex.: 256\n",
    "        outch: (int), Ex.: 128\n",
    "    '''\n",
    "    def __init__(self, out_size, inch, outch, final=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if final:\n",
    "            layers = [\n",
    "                MiniBatchStd(), # final block only\n",
    "                Conv2d(inch+1, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "                Conv2d(outch, outch, 4, padding=0), \n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "                nn.Conv2d(outch, 1, 1, padding=0), \n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                Conv2d(inch, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "                Conv2d(outch, outch, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=False),\n",
    "                nn.AdaptiveAvgPool2d((out_size, out_size)),\n",
    "            ]\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # conv modules & toRGBs\n",
    "        scale = 1\n",
    "        inchs  = np.array([512,256,128,64,32,16], dtype=np.uint32)*scale\n",
    "        outchs = np.array([256,128, 64,32,16, 8], dtype=np.uint32)*scale\n",
    "        sizes = np.array([4,8,16,32,64,128], dtype=np.uint32)\n",
    "        firsts = np.array([True, False, False, False, False, False], dtype=np.bool)\n",
    "        blocks, toRGBs = [], []\n",
    "        for s, inch, outch, first in zip(sizes, inchs, outchs, firsts):\n",
    "            blocks.append(ConvModuleG(s, inch, outch, first))\n",
    "            toRGBs.append(nn.Conv2d(outch, 3, 1, padding=0))\n",
    "\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.toRGBs = nn.ModuleList(toRGBs)\n",
    "\n",
    "    def forward(self, x, res, eps=1e-7):\n",
    "        # to image\n",
    "        n,c = x.shape\n",
    "        x = x.reshape(n,c//16,4,4)\n",
    "\n",
    "        # for the highest resolution\n",
    "        res = min(res, len(self.blocks))\n",
    "\n",
    "        # get integer by floor\n",
    "        nlayer = max(int(res-eps), 0)\n",
    "        for i in range(nlayer):\n",
    "            x = self.blocks[i](x)\n",
    "\n",
    "        # high resolution\n",
    "        x_big = self.blocks[nlayer](x)\n",
    "        dst_big = self.toRGBs[nlayer](x_big)\n",
    "\n",
    "        if nlayer==0:\n",
    "            x = dst_big\n",
    "        else:\n",
    "            # low resolution\n",
    "            x_sml = F.interpolate(x, x_big.shape[2:4], mode='nearest')\n",
    "            dst_sml = self.toRGBs[nlayer-1](x_sml)\n",
    "            alpha = res - int(res-eps)\n",
    "            x = (1-alpha)*dst_sml + alpha*dst_big\n",
    "\n",
    "        #return x, n, res\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.minbatch_std = MiniBatchStd()\n",
    "\n",
    "        # conv modules & toRGBs\n",
    "        scale = 1\n",
    "        inchs = np.array([256,128, 64,32,16, 8], dtype=np.uint32)*scale\n",
    "        outchs  = np.array([512,256,128,64,32,16], dtype=np.uint32)*scale\n",
    "        sizes = np.array([1,4,8,16,32,64], dtype=np.uint32)\n",
    "        finals = np.array([True, False, False, False, False, False], dtype=np.bool)\n",
    "        blocks, fromRGBs = [], []\n",
    "        for s, inch, outch, final in zip(sizes, inchs, outchs, finals):\n",
    "            fromRGBs.append(nn.Conv2d(3, inch, 1, padding=0))\n",
    "            blocks.append(ConvModuleD(s, inch, outch, final=final))\n",
    "\n",
    "        self.fromRGBs = nn.ModuleList(fromRGBs)\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, x, res):\n",
    "        # for the highest resolution\n",
    "        res = min(res, len(self.blocks))\n",
    "\n",
    "        # get integer by floor\n",
    "        eps = 1e-7\n",
    "        n = max(int(res-eps), 0)\n",
    "\n",
    "        # high resolution\n",
    "        x_big = self.fromRGBs[n](x)\n",
    "        x_big = self.blocks[n](x_big)\n",
    "\n",
    "        if n==0:\n",
    "            x = x_big\n",
    "        else:\n",
    "            # low resolution\n",
    "            x_sml = F.adaptive_avg_pool2d(x, x_big.shape[2:4])\n",
    "            x_sml = self.fromRGBs[n-1](x_sml)\n",
    "            alpha = res - int(res-eps)\n",
    "            x = (1-alpha)*x_sml + alpha*x_big\n",
    "\n",
    "        for i in range(n):\n",
    "            x = self.blocks[n-1-i](x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(netD, real, fake, res, batch_size, gamma=1):\n",
    "    device = real.device\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, requires_grad=True).to(device)\n",
    "    x = alpha*real + (1-alpha)*fake\n",
    "    d_ = netD.forward(x, res)\n",
    "    g = torch.autograd.grad(outputs=d_, inputs=x,\n",
    "                            grad_outputs=torch.ones(d_.shape).to(device),\n",
    "                            create_graph=True, retain_graph=True,only_inputs=True)[0]\n",
    "    g = g.reshape(batch_size, -1)\n",
    "    return ((g.norm(2,dim=1)/gamma-1.0)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-001a9c54c699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     trainset = datasets.CelebA('~/data', download=True, split='train',\n\u001b[1;32m---> 18\u001b[1;33m                                transform=transform)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PGGAN\\lib\\site-packages\\torchvision\\datasets\\celeba.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     ) -> None:\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         super(CelebA, self).__init__(root, transform=transform,\n\u001b[0;32m     63\u001b[0m                                      target_transform=target_transform)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    netG = Generator().to(device) #  models.Generator().to(device)\n",
    "    netD = Discriminator().to(device) # models.Discriminator().to(device)\n",
    "    netG_mavg = Generator().to(device) # models.Generator().to(device) # moving average\n",
    "    optG = torch.optim.Adam(netG.parameters(), lr=0.0005, betas=(0.0, 0.99))\n",
    "    optD = torch.optim.Adam(netD.parameters(), lr=0.0005, betas=(0.0, 0.99))\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    # dataset\n",
    "    transform = transforms.Compose([transforms.CenterCrop(160),\n",
    "                                    transforms.Resize((128,128)),\n",
    "                                    transforms.ToTensor(), ])\n",
    "\n",
    "    trainset = datasets.CelebA('~/data', download=True, split='train',\n",
    "                               transform=transform)\n",
    "\n",
    "    bs = 8\n",
    "    train_loader = DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "\n",
    "    # training\n",
    "    nepoch = 10\n",
    "    losses = []\n",
    "    res_step = 15000\n",
    "    j = 0\n",
    "    # constant random inputs\n",
    "    z0 = torch.randn(16, 512*16).to(device)\n",
    "    z0 = torch.clamp(z0, -1.,1.)\n",
    "    for iepoch in range(nepoch):\n",
    "        if j==res_step*6.5:\n",
    "            optG.param_groups[0]['lr'] = 0.0001\n",
    "            optD.param_groups[0]['lr'] = 0.0001\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            res = j/res_step\n",
    "\n",
    "            ### train generator ###\n",
    "            z = torch.randn(bs, 512*16).to(x.device)\n",
    "            x_ = netG.forward(z, res)\n",
    "            d_ = netD.forward(x_, res) # fake\n",
    "            lossG = -d_.mean() # WGAN_GP\n",
    "\n",
    "            optG.zero_grad()\n",
    "            lossG.backward()\n",
    "            optG.step()\n",
    "\n",
    "            # update netG_mavg by moving average\n",
    "            momentum = 0.995 # remain momentum\n",
    "            alpha = min(1.0-(1/(j+1)), momentum)\n",
    "            for p_mavg, p in zip(netG_mavg.parameters(), netG.parameters()):\n",
    "                p_mavg.data = alpha*p_mavg.data + (1.0-alpha)*p.data\n",
    "\n",
    "            ### train discriminator ###\n",
    "            z = torch.randn(x.shape[0], 512*16).to(x.device)\n",
    "            x_ = netG.forward(z, res)\n",
    "            x = F.adaptive_avg_pool2d(x, x_.shape[2:4])\n",
    "            d = netD.forward(x, res)   # real\n",
    "            d_ = netD.forward(x_, res) # fake\n",
    "            loss_real = -d.mean()\n",
    "            loss_fake = d_.mean()\n",
    "            loss_gp = gradient_penalty(netD, x.data, x_.data, res, x.shape[0])\n",
    "            loss_drift = (d**2).mean()\n",
    "\n",
    "            beta_gp = 10.0\n",
    "            beta_drift = 0.001\n",
    "            lossD = loss_real + loss_fake + beta_gp*loss_gp + beta_drift*loss_drift\n",
    "\n",
    "            optD.zero_grad()\n",
    "            lossD.backward()\n",
    "            optD.step()\n",
    "\n",
    "            print('ep: %02d %04d %04d lossG=%.10f lossD=%.10f' %\n",
    "                  (iepoch, i, j, lossG.item(), lossD.item()))\n",
    "\n",
    "            losses.append([lossG.item(), lossD.item()])\n",
    "            j += 1\n",
    "\n",
    "            if j%500==0:\n",
    "                netG_mavg.eval()\n",
    "                z = torch.randn(16, 512*16).to(x.device)\n",
    "                x_0 = netG_mavg.forward(z0, res)\n",
    "                x_ = netG_mavg.forward(z, res)\n",
    "\n",
    "                dst = torch.cat((x_0, x_), dim=0)\n",
    "                dst = F.interpolate(dst, (128, 128), mode='nearest')\n",
    "                dst = dst.to('cpu').detach().numpy()\n",
    "                n, c, h, w = dst.shape\n",
    "                dst = dst.reshape(4,8,c,h,w)\n",
    "                dst = dst.transpose(0,3,1,4,2)\n",
    "                dst = dst.reshape(4*h,8*w,3)\n",
    "                dst = np.clip(dst*255., 0, 255).astype(np.uint8)\n",
    "                skio.imsave('out/img_%03d_%05d.png' % (iepoch, j), dst)\n",
    "\n",
    "                losses_ = np.array(losses)\n",
    "                niter = losses_.shape[0]//100*100\n",
    "                x_iter = np.arange(100)*(niter//100) + niter//200\n",
    "                plt.plot(x_iter, losses_[:niter,0].reshape(100,-1).mean(1))\n",
    "                plt.plot(x_iter, losses_[:niter,1].reshape(100,-1).mean(1))\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('out/loss_%03d_%05d.png' % (iepoch, j))\n",
    "                plt.clf()\n",
    "\n",
    "                netG_mavg.train()\n",
    "\n",
    "            if j >= res_step*7:\n",
    "                break\n",
    "\n",
    "            if j%100==0:\n",
    "                coolGPU()\n",
    "\n",
    "        if j >= res_step*7:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
